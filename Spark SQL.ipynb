{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee549481",
   "metadata": {},
   "source": [
    "# Spark SQL\n",
    "\n",
    "Spark SQL is a module in Apache Spark for structured data processing. It allows you to run SQL queries on large datasets, combining the benefits of SQL with the scalability of Sparkâ€™s distributed computing capabilities.\n",
    "- In this work, Yelp academic datasets are used for data manipulation using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4efab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 18:55:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('My First Spark application') \\\n",
    "    .getOrCreate() \n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5598239",
   "metadata": {},
   "source": [
    "- Let's read our data which is json file of Yelp academic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4304d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/10/30 18:55:26 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_business.json.gz')\n",
    "checkin = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_checkin.json.gz')\n",
    "review = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_review.json.gz')\n",
    "tip = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_tip.json.gz')\n",
    "user = spark.read.json('../../assets/data/yelp_academic/yelp_academic_dataset_user.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e5b681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(business) # business is a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b740ed7",
   "metadata": {},
   "source": [
    "- To get ready to work with SQL commands on our Spark Session Data Frames, we can create a view onto our dataframes. Every Spark Session can have a view created. Either, temporary, permanent or global. \n",
    "- Here we consider a temporary view. Temporary views disappear after Spark Session ends. \n",
    "- Once we have a temp view, we can use it to issue  SQL querry view that we have created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5780f",
   "metadata": {},
   "source": [
    "# Create temp views for the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba870ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "business.createOrReplaceTempView(\"business\")\n",
    "checkin.createOrReplaceTempView(\"checkin\")\n",
    "tip.createOrReplaceTempView(\"tip\")\n",
    "review.createOrReplaceTempView(\"review\")\n",
    "user.createOrReplaceTempView(\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a39d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also read our state csv file which refers to US States and create a temp view for that as well: \n",
    "us_states = spark.read.option(\"header\",True).csv('../../assets/data/states.csv')\n",
    "us_states.createOrReplaceTempView(\"us_states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe1f456",
   "metadata": {},
   "source": [
    "# -- elite review --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24ee54",
   "metadata": {},
   "source": [
    "- Get a list of users named \"Jenna\" with the number of their reviews tagged \"elite\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db597a24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_cool: long (nullable = true)\n",
      " |-- compliment_cute: long (nullable = true)\n",
      " |-- compliment_funny: long (nullable = true)\n",
      " |-- compliment_hot: long (nullable = true)\n",
      " |-- compliment_list: long (nullable = true)\n",
      " |-- compliment_more: long (nullable = true)\n",
      " |-- compliment_note: long (nullable = true)\n",
      " |-- compliment_photos: long (nullable = true)\n",
      " |-- compliment_plain: long (nullable = true)\n",
      " |-- compliment_profile: long (nullable = true)\n",
      " |-- compliment_writer: long (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- elite: string (nullable = true)\n",
      " |-- fans: long (nullable = true)\n",
      " |-- friends: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- yelping_since: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1041e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+----+--------------+----+--------------------+-----+------+------------+------+--------------------+-------------------+\n",
      "|average_stars|compliment_cool|compliment_cute|compliment_funny|compliment_hot|compliment_list|compliment_more|compliment_note|compliment_photos|compliment_plain|compliment_profile|compliment_writer|cool|         elite|fans|             friends|funny|  name|review_count|useful|             user_id|      yelping_since|\n",
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+----+--------------+----+--------------------+-----+------+------------+------+--------------------+-------------------+\n",
      "|         4.03|              1|              0|               1|             2|              0|              0|              1|                0|               1|                 0|                2|  25|2015,2016,2017|   5|c78V-rj8NQcQjOI8K...|   17|Rashmi|          95|    84|l6BmjZMeQD3rDxWUb...|2013-10-08 23:11:33|\n",
      "|         3.63|              1|              0|               1|             1|              0|              0|              0|                0|               0|                 0|                0|  16|              |   4|kEBTgDvFX754S68Fl...|   22| Jenna|          33|    48|4XChL029mKr5hydo7...|2013-02-21 22:29:06|\n",
      "+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+----+--------------+----+--------------------+-----+------+------------+------+--------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40a1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT user_id, name, fans \n",
    "FROM user\n",
    "WHERE name ='Jenna'\n",
    "ORDER BY fans DESC\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d64a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+\n",
      "|             user_id| name|fans|\n",
      "+--------------------+-----+----+\n",
      "|bEX-LmV3ViAbv7mK_...|Jenna| 115|\n",
      "|VRvD7-JHdWdTQnh1l...|Jenna| 100|\n",
      "|QpbySlIOUOkrT9YeV...|Jenna|  93|\n",
      "|kxj7TPtJY2zbEjGV0...|Jenna|  84|\n",
      "|WH612ezymlanNW5oB...|Jenna|  67|\n",
      "+--------------------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5214a",
   "metadata": {},
   "source": [
    "# -- USERS WITH    more than 1000     FANS --\n",
    "\n",
    "- Let's find out the number of users that have more than 1000 fans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e918b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SPARK DataFrame functions:\n",
    "user.filter(user['fans']>1000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f1cf893",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT count(user_id)\n",
    "FROM user\n",
    "WHERE fans > 1000\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8a0b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|count(user_id)|\n",
      "+--------------+\n",
      "|            46|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb4049",
   "metadata": {},
   "source": [
    "# -- Review Star Business --\n",
    "\n",
    "- Let's find out the number of businesses with at least 4 stars and at least 100 review_count.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5be1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+-------+-------------+-------------+--------------------+-----------+------------+-----+-----+\n",
      "|             address|          attributes|         business_id|          categories|       city|               hours|is_open|     latitude|    longitude|                name|postal_code|review_count|stars|state|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+-------+-------------+-------------+--------------------+-----------+------------+-----+-----+\n",
      "|2818 E Camino Ace...|{null, null, null...|1SWheh84yJXfytovI...|   Golf, Active Life|    Phoenix|                null|      0|   33.5221425| -112.0184807|Arizona Biltmore ...|      85016|           5|  3.0|   AZ|\n",
      "|30 Eglinton Avenue W|{null, null, u'fu...|QXAEGFB4oINsVuTFx...|Specialty Food, R...|Mississauga|{9:0-1:0, 9:0-0:0...|      1|43.6054989743|-79.652288909|Emerald Chinese R...|    L5R 3E7|         128|  2.5|   ON|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------+--------------------+-------+-------------+-------------+--------------------+-----------+------------+-----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b796640",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT count(business_id) AS Num_business\n",
    "FROM business\n",
    "WHERE review_count >= 100 AND stars >= 4\n",
    "\"\"\"\n",
    "result = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca48e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Num_business|\n",
      "+------------+\n",
      "|        7464|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8cee98",
   "metadata": {},
   "source": [
    "# -- LITCHFIELD OHIO --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9932016b",
   "metadata": {},
   "source": [
    "- Get a list of businesses from Litchfield, OH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21bd957",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['address',\n",
       " 'attributes',\n",
       " 'business_id',\n",
       " 'categories',\n",
       " 'city',\n",
       " 'hours',\n",
       " 'is_open',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'name',\n",
       " 'postal_code',\n",
       " 'review_count',\n",
       " 'stars',\n",
       " 'state']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21d4133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OH_business():\n",
    "    return spark.sql(\"\"\"\\\n",
    "    SELECT business_id, name, city, state\n",
    "    FROM business\n",
    "    WHERE city = 'Litchfield' AND state = 'OH'\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd490251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+-----+\n",
      "|         business_id|                name|      city|state|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "|ucY9cyJinEaPfXZWA...|   T.L. Keller Meats|Litchfield|   OH|\n",
      "|t1w3AgvdlXCGAaTTT...|       Gizmos Grille|Litchfield|   OH|\n",
      "|_sRy_DqdGrUWqqYsr...|Old School House ...|Litchfield|   OH|\n",
      "|bRS8vlTZmdGGxF9vi...|           Gary Mart|Litchfield|   OH|\n",
      "|3NzMmFv3Ky_cxtL9Y...|        Tonios Pizza|Litchfield|   OH|\n",
      "|CFs89vckryf0WNb6z...|         Hungry Bear|Litchfield|   OH|\n",
      "+--------------------+--------------------+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "OH_Business_sql = OH_business()\n",
    "OH_Business_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd2a9c",
   "metadata": {},
   "source": [
    "# -- US STATES IN BUSINESS --\n",
    "\n",
    "- Find out which US states are represented in the business data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4e12ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_function ():\n",
    "    return spark.sql(\"\"\"\n",
    "        SELECT DISTINCT us_states.state\n",
    "        FROM us_states\n",
    "        JOIN business \n",
    "        ON business.state = us_states.abbreviation\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2cd65ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|         state|\n",
      "+--------------+\n",
      "|          Utah|\n",
      "|          Ohio|\n",
      "|      Arkansas|\n",
      "|         Texas|\n",
      "|  Pennsylvania|\n",
      "|   Connecticut|\n",
      "|      Nebraska|\n",
      "|       Vermont|\n",
      "|        Nevada|\n",
      "|    Washington|\n",
      "|      Illinois|\n",
      "|        Alaska|\n",
      "|    New Mexico|\n",
      "|       Georgia|\n",
      "|      Virginia|\n",
      "|North Carolina|\n",
      "|    New Jersey|\n",
      "|       Alabama|\n",
      "|       Arizona|\n",
      "|     Tennessee|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "state_business = state_function()\n",
    "state_business.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8685ef30",
   "metadata": {},
   "source": [
    "# -- FUNNIEST REVIEW --\n",
    "\n",
    "- Let's retrieve the text of the funniest review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48fb2eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|funny|\n",
      "+-----+\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.select('funny').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d39fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funniest_review():\n",
    "    return spark.sql(\"\"\"\\\n",
    "            SELECT text  \n",
    "            FROM review\n",
    "            WHERE funny = (SELECT max(funny) from review)\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4eacd2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Flew to Arizona a...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "funniest_rev = funniest_review()\n",
    "funniest_rev.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047465d8",
   "metadata": {},
   "source": [
    "## -- NAME OF MOST TIPS --\n",
    "\n",
    "- Let's find the names of the top 100 users who provided the most tips.\n",
    "- The result should be sorted by highest-to-lowest tip_count. However, in the case of tip_count ties, the results should be sorted by name alphabetically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ec3efbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['average_stars',\n",
       " 'compliment_cool',\n",
       " 'compliment_cute',\n",
       " 'compliment_funny',\n",
       " 'compliment_hot',\n",
       " 'compliment_list',\n",
       " 'compliment_more',\n",
       " 'compliment_note',\n",
       " 'compliment_photos',\n",
       " 'compliment_plain',\n",
       " 'compliment_profile',\n",
       " 'compliment_writer',\n",
       " 'cool',\n",
       " 'elite',\n",
       " 'fans',\n",
       " 'friends',\n",
       " 'funny',\n",
       " 'name',\n",
       " 'review_count',\n",
       " 'useful',\n",
       " 'user_id',\n",
       " 'yelping_since']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ff4b9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id', 'compliment_count', 'date', 'text', 'user_id']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac140c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT user.name, user.user_id, count(tip.date) AS tip_count \n",
    "    FROM user\n",
    "    JOIN tip ON tip.user_id=user.user_id\n",
    "    GROUP BY user.name, user.user_id\n",
    "    ORDER BY tip_count DESC, name ASC\"\"\"\n",
    "\n",
    "result = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1f9708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------+\n",
      "|    name|             user_id|tip_count|\n",
      "+--------+--------------------+---------+\n",
      "|    Momo|mkbx55W8B8aPLgDqe...|     2439|\n",
      "|Jennifer|CxDOIDnH8gp9KXzpB...|     1598|\n",
      "|Samantha|6ZC-0LfOAGwaFc5XP...|     1509|\n",
      "|  Daniel|0tvCcnfJnSs55iB6m...|     1376|\n",
      "|Christie|eZfHm0qI8A_HfvXSc...|     1352|\n",
      "|     May|O8eDScRAg6ae0l9Bc...|     1255|\n",
      "|   Kurdy|8DGFWco9VeBAxjqsu...|     1178|\n",
      "| Anthony|WJKocp9RE0KatUwh3...|     1161|\n",
      "| Shirley|2EuPAGalYnP7eSxPg...|     1154|\n",
      "| Cherrie|QPJJohtGqkMkaN0Gt...|     1017|\n",
      "|  Nelson|3nDUQBjKyVor5wV0r...|     1002|\n",
      "|    John|5dKknvq65x-SaluuJ...|      997|\n",
      "| Georgie|A0j21z2Q1HGic7jW6...|      986|\n",
      "|   Roger|0FMte0z-repSVWSJ_...|      925|\n",
      "|   Vegas|uG35h72BAMutvXAWd...|      846|\n",
      "|    Tony|RQlnSCjuqMnhR3Qk6...|      820|\n",
      "| Stephen|tQPk4JiBPsx7NSIDb...|      794|\n",
      "|  Alfred|Fw4UjJ6yBeyPB27Y4...|      793|\n",
      "|  Arlene|fmzIm7RxEdii5Jz44...|      773|\n",
      "| Colanie|pn_flI3EBNugBEYFp...|      771|\n",
      "+--------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7565d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|    name|tip_count|\n",
      "+--------+---------+\n",
      "|    Momo|     2439|\n",
      "|Jennifer|     1598|\n",
      "|Samantha|     1509|\n",
      "|  Daniel|     1376|\n",
      "|Christie|     1352|\n",
      "+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def name_most_tips():\n",
    "    return spark.sql(\"\"\"\n",
    "        SELECT user.name, count(user.user_id) as tip_count  \n",
    "        FROM tip\n",
    "        join user on user.user_id = tip.user_id\n",
    "        group by name, user.user_id\n",
    "        ORDER BY tip_count DESC, name ASC\n",
    "        \"\"\")\n",
    "\n",
    "most_tips = name_most_tips()\n",
    "most_tips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8abfe8f",
   "metadata": {},
   "source": [
    "## -- NEW YORK SUMMARY -- \n",
    "\n",
    "- Let's figure out the list of user names and number of reviews of businesses in NewYork ('NY') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33fc9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_review():\n",
    "    return spark.sql(\"\"\"\n",
    "        SELECT user.name, count(review.business_id) FILTER(WHERE state = 'NY') AS ny_count\n",
    "        FROM user\n",
    "\n",
    "        JOIN review ON review.user_id = user.user_id \n",
    "\n",
    "        JOIN business ON business.business_id = review.business_id\n",
    "\n",
    "        GROUP BY user.name, user.user_id\n",
    "\n",
    "        ORDER BY ny_count DESC\"\"\"\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca859c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|   name|ny_count|\n",
      "+-------+--------+\n",
      "|  Stacy|       4|\n",
      "|Stephen|       4|\n",
      "|  Sarah|       4|\n",
      "|    lou|       2|\n",
      "|Matthew|       2|\n",
      "| Rachel|       2|\n",
      "|  Amber|       2|\n",
      "|  Trina|       2|\n",
      "|  Henry|       2|\n",
      "| Nicole|       2|\n",
      "|Katelyn|       2|\n",
      "|   Skip|       2|\n",
      "|  Megan|       2|\n",
      "| Millie|       2|\n",
      "|      R|       2|\n",
      "|      K|       2|\n",
      "|Mallory|       2|\n",
      "|   Matt|       2|\n",
      "|      G|       2|\n",
      "|  Brian|       2|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "name_review = name_review()\n",
    "name_review.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767137c",
   "metadata": {},
   "source": [
    "## -- NEW YORK SUMMARY -- \n",
    "\n",
    "- Now, we can find the user names, number of reviews of businesses in New York ('NY') and total number of reviews of the top 10 users (as determined by who has created the most number of reviews of businesses in New York). Include a column that shows the percentage of reviews that are of businesses from New York. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5165e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_review_percent():\n",
    "    return spark.sql(\"\"\"\n",
    "            SELECT user.name, count(review.business_id) FILTER(WHERE state = 'NY') AS ny_count,\n",
    "            user.review_count AS total_review,\n",
    "            ROUND(count(review.business_id) FILTER(WHERE state = 'NY') *100 / (user.review_count), 2) AS percent\n",
    "\n",
    "            FROM user\n",
    "\n",
    "            JOIN review \n",
    "            ON review.user_id = user.user_id \n",
    "\n",
    "            JOIN business \n",
    "            ON review.business_id = business.business_id   \n",
    "\n",
    "            GROUP BY user.name, user.user_id, user.review_count\n",
    "\n",
    "            ORDER BY ny_count DESC, total_review DESC\n",
    "            LIMIT 10\"\"\"\n",
    "                    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c7c928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+-------+\n",
      "|   name|ny_count|total_review|percent|\n",
      "+-------+--------+------------+-------+\n",
      "|  Sarah|       4|         337|   1.19|\n",
      "|  Stacy|       4|           8|   50.0|\n",
      "|Stephen|       4|           8|   50.0|\n",
      "|  Amber|       2|         617|   0.32|\n",
      "|Katelyn|       2|          78|   2.56|\n",
      "+-------+--------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "    \n",
    "name_review = name_review_percent()\n",
    "name_review.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591b93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
